P8105 Homework 3
================
November 15th, 2022

## Part 1:

## Part 2: U.S. Homicide Rates

Let’s load the raw homicide data and inspect it.

``` r
homicide_data = read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names()

homicide_data
```

    ## # A tibble: 52,179 × 12
    ##    uid   repor…¹ victi…² victi…³ victi…⁴ victi…⁵ victi…⁶ city  state   lat   lon
    ##    <chr>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr> <chr> <dbl> <dbl>
    ##  1 Alb-…  2.01e7 GARCIA  JUAN    Hispan… 78      Male    Albu… NM     35.1 -107.
    ##  2 Alb-…  2.01e7 MONTOYA CAMERON Hispan… 17      Male    Albu… NM     35.1 -107.
    ##  3 Alb-…  2.01e7 SATTER… VIVIANA White   15      Female  Albu… NM     35.1 -107.
    ##  4 Alb-…  2.01e7 MENDIO… CARLOS  Hispan… 32      Male    Albu… NM     35.1 -107.
    ##  5 Alb-…  2.01e7 MULA    VIVIAN  White   72      Female  Albu… NM     35.1 -107.
    ##  6 Alb-…  2.01e7 BOOK    GERALD… White   91      Female  Albu… NM     35.2 -107.
    ##  7 Alb-…  2.01e7 MALDON… DAVID   Hispan… 52      Male    Albu… NM     35.1 -107.
    ##  8 Alb-…  2.01e7 MALDON… CONNIE  Hispan… 52      Female  Albu… NM     35.1 -107.
    ##  9 Alb-…  2.01e7 MARTIN… GUSTAVO White   56      Male    Albu… NM     35.1 -107.
    ## 10 Alb-…  2.01e7 HERRERA ISRAEL  Hispan… 43      Male    Albu… NM     35.1 -107.
    ## # … with 52,169 more rows, 1 more variable: disposition <chr>, and abbreviated
    ## #   variable names ¹​reported_date, ²​victim_last, ³​victim_first, ⁴​victim_race,
    ## #   ⁵​victim_age, ⁶​victim_sex

There are 52179 observations of 12 variables containing information
about homicides in 50 cities across the US. The data contains the date,
victim information (name, age, sex, race), location (city, state,
latitude, longitude), and status of the case.

Next, let’s summarize the data within cities to obtain the total number
of homicides and the number of unsolved homicides.

``` r
homicide_summary = homicide_data %>% 
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, state, sep = ", "), 
    status = ifelse(
      disposition == "Closed without arrest" | disposition == "Open/No arrest", "Solved", "Unsolved")) %>% 
  group_by(city_state) %>% 
  summarise(n_unsolved = sum(status == "Unsolved"), 
            n_total = n()) 

homicide_summary
```

    ## # A tibble: 51 × 3
    ##    city_state      n_unsolved n_total
    ##    <chr>                <int>   <int>
    ##  1 Albuquerque, NM        232     378
    ##  2 Atlanta, GA            600     973
    ##  3 Baltimore, MD         1002    2827
    ##  4 Baton Rouge, LA        228     424
    ##  5 Birmingham, AL         453     800
    ##  6 Boston, MA             304     614
    ##  7 Buffalo, NY            202     521
    ##  8 Charlotte, NC          481     687
    ##  9 Chicago, IL           1462    5535
    ## 10 Cincinnati, OH         385     694
    ## # … with 41 more rows

Next, for the city of Baltimore, MD, we will use the `prop.test`
function to estimate the proportion of homicides that are unsolved and
its confidence interval.

``` r
baltimore_df = homicide_summary %>% 
  filter(city_state == "Baltimore, MD") 

x = baltimore_df %>% pull(n_unsolved)
n = baltimore_df %>% pull(n_total)
  
baltimore_est = prop.test(x, n) 

baltimore_est %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high) %>% 
  mutate_all(~ . * 100) %>% 
  rename("Estimated proportion of unsolved homicides" = estimate,
         "Lower confidence limit" = conf.low, 
         "Upper confidence limit" = conf.high)
```

    ## # A tibble: 1 × 3
    ##   `Estimated proportion of unsolved homicides` `Lower confidence limit` Upper …¹
    ##                                          <dbl>                    <dbl>    <dbl>
    ## 1                                         35.4                     33.7     37.2
    ## # … with abbreviated variable name ¹​`Upper confidence limit`

We can see that the estimated proportion of of unsolved homicides in
Baltimore is 35.4439335%. We are 95% confident that the proportion of
unsolved homicides in Baltimore is between 33.684014% and 37.2437542%.

Next, we want use `map` to apply the `prop.test` function to estimate
the proportion of unsolved homicides in all cities in our dataset.

``` r
unsolved_homicides = homicide_summary %>% 
  mutate(
    prop_test = map2(.x = n_unsolved, .y = n_total, ~prop.test(x = .x, n = .y) %>% 
                       broom::tidy())) %>% 
  unnest(prop_test) %>% 
  select(city_state:estimate, conf.low, conf.high)

unsolved_homicides
```

    ## # A tibble: 51 × 6
    ##    city_state      n_unsolved n_total estimate conf.low conf.high
    ##    <chr>                <int>   <int>    <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM        232     378    0.614    0.562     0.663
    ##  2 Atlanta, GA            600     973    0.617    0.585     0.647
    ##  3 Baltimore, MD         1002    2827    0.354    0.337     0.372
    ##  4 Baton Rouge, LA        228     424    0.538    0.489     0.586
    ##  5 Birmingham, AL         453     800    0.566    0.531     0.601
    ##  6 Boston, MA             304     614    0.495    0.455     0.535
    ##  7 Buffalo, NY            202     521    0.388    0.346     0.431
    ##  8 Charlotte, NC          481     687    0.700    0.664     0.734
    ##  9 Chicago, IL           1462    5535    0.264    0.253     0.276
    ## 10 Cincinnati, OH         385     694    0.555    0.517     0.592
    ## # … with 41 more rows

The resulting `unsolved_homicides` dataframe contains 51 observations of
6 variables, providing number of unsolved and total homicides, and the
estimated proportion of unsolved homicides, along with their 95% CIs
which come from mapping the `prop.test` function to all the cities.

Finally, we will create a plot of the estimated proportions of unsolved
homicides in each city, along with their confidence intervals.

``` r
unsolved_homicides %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, colour = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = .3)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        legend.position = "none") + 
  labs(
    x = "Location",
    y = "Estimated proportion of unsolved homicides",
    title = "Proportion of homicides that are unsolved in 50 U.S. cities, 2007-2017",
  )
```

![](p8105_hw5_my2731_files/figure-gfm/plot-1.png)<!-- -->

## Part 3: Simulating parameters that affect power

A common question when designing experiments is whether a false null
hypothesis will be rejected, or what the power of a study will be. Power
depends on the sample size of our study, effect size, and error
variance. In this problem, we will conduct a simulation to explore power
in a one-sample t-test.

First, we will write a function that generates a random sample from a
normal distribution and outputs the results for a one-sample t-test of
$H_0: \mu = 0$ for $\alpha = 0.05$ on the sample mean. We will fix the
$n = 30$, $\sigma = 5$, and allow the $\mu$ to vary.

``` r
sim_t_test = function(true_mean) {
  
  sample = rnorm(n = 30, sd = 5, mean = true_mean)
  
  test_results = t.test(sample)
  
  test_results %>% 
    broom::tidy()
}
```

We will map the `sim_t_test` to a dataset of 5000 observations with a
true $\mu = 0$, and pull the estimated mean and p-value from the t-test
results.

``` r
sim_df = expand_grid(
  true_mean = 0,
  iterate = 1:50) %>% 
  mutate(ttest_df = map(true_mean, sim_t_test)) %>% 
  unnest(ttest_df) %>% 
  select(true_mean:estimate, p.value)


sim_df
```

    ## # A tibble: 50 × 4
    ##    true_mean iterate estimate p.value
    ##        <dbl>   <int>    <dbl>   <dbl>
    ##  1         0       1  -0.394   0.753 
    ##  2         0       2  -0.323   0.768 
    ##  3         0       3  -0.0952  0.925 
    ##  4         0       4  -0.713   0.374 
    ##  5         0       5  -0.388   0.652 
    ##  6         0       6   1.30    0.203 
    ##  7         0       7   1.20    0.260 
    ##  8         0       8  -0.882   0.284 
    ##  9         0       9   1.94    0.0251
    ## 10         0      10  -1.12    0.251 
    ## # … with 40 more rows
